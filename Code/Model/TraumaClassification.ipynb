{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95d9e50b",
   "metadata": {},
   "source": [
    "### Binary Classification Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ece6e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Statements\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import math\n",
    "import warnings\n",
    "import joblib\n",
    "import os\n",
    "import glob\n",
    "\n",
    "from sklearn import metrics, svm\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RepeatedStratifiedKFold, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
    "from sklearn.ensemble import BaggingRegressor, RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc1f8864",
   "metadata": {},
   "source": [
    "### Initializations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d440d806",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Box Folder Location containing data files\n",
    "\n",
    "home_dir = os.path.expanduser('~')\n",
    "\n",
    "apple_folder_loc = home_dir + \"/Library/CloudStorage/Box-Box/Capstone/Capstone/Data Science Capstone/Data\"\n",
    "windows_folder_loc = home_dir + \"~/Box/Capstone/Capstone/Data Science Capstone/Data\"\n",
    "linux_folder_loc = \"\"\n",
    "\n",
    "data_folder_loc = apple_folder_loc if sys.platform.startswith(\"darwin\") else (windows_folder_loc if sys.platform.startswith(\"win\") else linux_folder_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "878309c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_to_read_for_input_files = \"FeatureSelection\"\n",
    "folder_to_save_model = \"Models\"\n",
    "random_state = 265\n",
    "reporting_df = pd.DataFrame(columns=['File Name', 'Model', 'Accuracy', 'Precision_Recall', 'R-Square', 'Adjusted-R-Square'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "833f2bb0",
   "metadata": {},
   "source": [
    "### Functions to automate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a240721",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(file_path):\n",
    "    \n",
    "    print(\"\\nLoading File {}\\n\".format(file_path.split(\"/\")[-1]))\n",
    "    \n",
    "    data = pd.read_excel(file_path)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05806040",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_train_test_split(X, Y, test_size=0.30, random_state=1):\n",
    "    \n",
    "    print(\"Performing {}/{} Train-Test Split\".format((1-test_size) * 100, test_size * 100))\n",
    "    return train_test_split(X, Y, test_size=test_size, random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "55cf35f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_classification_report(X_test, y_test, y_pred):\n",
    "    \n",
    "    print(\"\\nFinding Classification Report\\n\")\n",
    "    \n",
    "    r_sq = metrics.r2_score(y_pred, y_test)\n",
    "    adj_r_sq = 1 - (1 - metrics.r2_score(y_test, y_pred)) * ((len(X_test) - 1) / (len(X_test) - X_test.shape[1] - 1))\n",
    "    \n",
    "    report = metrics.classification_report(y_test, y_pred, output_dict=True)\n",
    "    report['R-Square'] = r_sq\n",
    "    report['Adjusted-R-Square'] = adj_r_sq\n",
    "    \n",
    "    return report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b91422da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, file_name, model_name):\n",
    "    \n",
    "    print(\"\\nSaving model {} \\n\".format(model_name))\n",
    "    \n",
    "    joblib.dump(model, \"{}/{}/{}_{}\".format(data_folder_loc, folder_to_save_model, file_name.split(\".xlsx\")[0], model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7374f122",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model, model_name):\n",
    "    \n",
    "    print(\"\\nLoading Model {}\\n\", model_name)\n",
    "    \n",
    "    return joblib.load(\"{}/{}/{}\".format(data_folder_loc, folder_to_save_model, model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "216058f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_report(X_test, y_test, y_pred, model, model_name, file_name, reporting_df):\n",
    "    classification_report = get_classification_report(X_test, y_test, y_pred)\n",
    "    reporting_df = reporting_df.append(\n",
    "        {\n",
    "            'File Name': file_name,\n",
    "            'Model': model_name,\n",
    "            'Accuracy': classification_report['accuracy'],\n",
    "            'Precision_Recall': {'0': classification_report['0'], '1': classification_report['1']},\n",
    "            'R-Square': classification_report['R-Square'],\n",
    "            'Adjusted-R-Square': classification_report['Adjusted-R-Square']\n",
    "        },\n",
    "        ignore_index=True\n",
    "    )\n",
    "    save_model(model, file_name, model_name)\n",
    "    return reporting_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30aff9ec",
   "metadata": {},
   "source": [
    "### OverSampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6603000d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_oversampling():\n",
    "    \n",
    "    print(\"\\nPerforming Oversampling since data labels are distributed as follows:\\n\")\n",
    "    data_labels.value_counts()\n",
    "    \n",
    "    return RandomOverSampler().fit_resample(data_features, data_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c5547b",
   "metadata": {},
   "source": [
    "### Stratified Sampling with Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6b3f86e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_stratified_sampling(X, y, model, n_splits=10, n_repeats=3, n_jobs=-1):\n",
    "    \n",
    "    cv = RepeatedStratifiedKFold(n_splits=n_splits, n_repeats=n_repeats, random_state=random_state)\n",
    "    n_scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=n_jobs, error_score='raise')\n",
    "\n",
    "    print('Accuracy: %.3f (%.3f)' % (np.mean(n_scores), np.std(n_scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f44d05b5",
   "metadata": {},
   "source": [
    "### Bagging Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "84158427",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_bagging(X_train, y_train, X_test, y_test, model, n_estimators, file_name, reporting_df):\n",
    "    \n",
    "    print(\"\\nPerforming Bagging Regression\\n\")\n",
    "    \n",
    "    bagging_model = BaggingRegressor(model, n_estimators=n_estimators)\n",
    "    bagging_model.fit(X_train, y_train)\n",
    "\n",
    "    test_preds_grid = bagging_model.predict(X_test)\n",
    "    y_pred = np.round(test_preds_grid).astype(int)\n",
    "    \n",
    "    return make_report(X_test, y_test, y_pred, bagging_model, \"Bagging Regressor\", file_name, reporting_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1683e67d",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2e55a113",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_logistic_regression(X_train, y_train, X_test, y_test, file_name, reporting_df):\n",
    "    \n",
    "    print(\"\\nPerforming Logistic Regression\\n\")\n",
    "    \n",
    "    logreg = LogisticRegression(random_state=random_state)\n",
    "    logreg.fit(X_train, y_train)\n",
    "    y_pred = logreg.predict(X_test)\n",
    "    \n",
    "    logit_model = sm.Logit(data_labels, data_features)\n",
    "    result = logit_model.fit()\n",
    "    print(\"\\nSummary for Logit Model:\\n\\n\", result.summary2())\n",
    "    \n",
    "    return make_report(X_test, y_test, y_pred, logreg, \"Logistic Regression\", file_name, reporting_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c20f0b8",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7dfacc71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_svm(X_train, y_train, X_test, y_test, file_name, reporting_df):\n",
    "    \n",
    "    print(\"\\nPerforming SVM Classification\\n\")\n",
    "    \n",
    "    parameters= {'kernel': ('linear', 'rbf', 'poly'), 'C': [1, 10, 100], 'degree': [2]}\n",
    "    \n",
    "    gridsearch = GridSearchCV(svm.SVC(), parameters)\n",
    "    gridsearch.fit(X_train, y_train)\n",
    "    \n",
    "    best_kernel, best_c = gridsearch.best_params_['kernel'], gridsearch.best_params_['C']\n",
    "    print(gridsearch.best_params_)\n",
    "    best_model = svm.SVC(kernel=best_kernel, C=best_c)\n",
    "    \n",
    "    if best_kernel == 'linear':\n",
    "        \n",
    "        print('\\nw = ',gridsearch.coef_)\n",
    "        print('\\nb = ',gridsearch.intercept_)\n",
    "        print('\\nIndices of support vectors = ', gridsearch.support_)\n",
    "        print('\\nSupport vectors = ', gridsearch.support_vectors_)\n",
    "        print('\\nNumber of support vectors for each class = ', gridsearch.n_support_)\n",
    "        print('\\nCoefficients of the support vector in the decision function = ', np.abs(gridsearch.dual_coef_))        \n",
    "    \n",
    "    elif best_kernel == 'poly':\n",
    "        best_degree = gridsearch.best_params_['degree']\n",
    "        best_model = svm.SVC(kernel=best_kernel, C=best_c, degree=best_degree)\n",
    "    \n",
    "    best_model.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = best_model.predict(X_test)\n",
    "    y_pred = np.round(y_pred).astype(int)\n",
    "    \n",
    "    return make_report(X_test, y_test, y_pred, best_model, \"SVM\", file_name, reporting_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a71be22",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19809189",
   "metadata": {},
   "source": [
    "#### KNN Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "92855059",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_knn_regressor(X_train, y_train, X_test, y_test, file_name, reporting_df):\n",
    "    \n",
    "    print(\"\\nPerforming KNN Regression\\n\")\n",
    "    \n",
    "    parameters = {\"n_neighbors\": range(1, 50), \"weights\": [\"uniform\", \"distance\"]}\n",
    "    gridsearch = GridSearchCV(KNeighborsRegressor(), parameters)\n",
    "    gridsearch.fit(X_train, y_train)\n",
    "    \n",
    "    best_n_neighbors, best_weight_technique = gridsearch.best_params_['n_neighbors'], gridsearch.best_params_['weights']\n",
    "    print(gridsearch.best_params_)\n",
    "    best_model = KNeighborsRegressor(n_neighbors=best_n_neighbors, weights=best_weight_technique)\n",
    "    best_model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    y_pred = np.round(y_pred).astype(int)\n",
    "    \n",
    "    return make_report(X_test, y_test, y_pred, best_model, \"KNN Regressor\", file_name, reporting_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdaf8ecd",
   "metadata": {},
   "source": [
    "#### KNN Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1b59b2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_knn_classifier(X_train, y_train, X_test, y_test, file_name, reporting_df):\n",
    "    \n",
    "    print(\"\\nPerforming KNN Classification\\n\")\n",
    "    \n",
    "    parameters = {\"n_neighbors\": range(1, 50), \"weights\": [\"uniform\", \"distance\"]}\n",
    "    \n",
    "    gridsearch = GridSearchCV(KNeighborsClassifier(), parameters)\n",
    "    gridsearch.fit(X_train, y_train)\n",
    "\n",
    "    print(\"{} Features used during classification: {}\".format(gridsearch.n_features_in_, gridsearch.feature_names_in_))\n",
    "\n",
    "    best_n_neighbors, best_weight_technique = gridsearch.best_params_['n_neighbors'], gridsearch.best_params_['weights']\n",
    "    print(gridsearch.best_params_)\n",
    "    best_model = KNeighborsClassifier(n_neighbors=best_n_neighbors, weights=best_weight_technique)\n",
    "    best_model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    y_pred = np.round(y_pred).astype(int)\n",
    "    \n",
    "    return make_report(X_test, y_test, y_pred, best_model, \"KNN Classifier\", file_name, reporting_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca85b0ab",
   "metadata": {},
   "source": [
    "### RandomForest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "378b94a9",
   "metadata": {},
   "source": [
    "#### Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "55834b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_random_forest_regressor(X_train, y_train, X_test, y_test, file_name, reporting_df, n_estimators=1000):\n",
    "    \n",
    "    print(\"\\nPerforming Random Forest Regression\\n\")\n",
    "    \n",
    "    rf = RandomForestRegressor(n_estimators = n_estimators, random_state = random_state)\n",
    "    rf.fit(X_train, y_train)\n",
    "    predictions = rf.predict(X_test)\n",
    "    y_pred = np.round(predictions).astype(int)\n",
    "    \n",
    "    # Get numerical feature importances\n",
    "    importances = list(rf.feature_importances_)\n",
    "\n",
    "    # List of tuples with variable and importance\n",
    "    feature_importances = [(feature, round(importance, 2)) for feature, importance in zip(X_train.columns, importances)]\n",
    "\n",
    "    # Sort the feature importances by most important first\n",
    "    feature_importances = sorted(feature_importances, key = lambda x: x[1], reverse = True)\n",
    "\n",
    "    # Print out the feature and importances \n",
    "    [print('Variable: {:20} Importance: {}'.format(*pair)) for pair in feature_importances];\n",
    "\n",
    "    return make_report(X_test, y_test, y_pred, rf, \"RandomForest Regressor\", file_name, reporting_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "062a88dc",
   "metadata": {},
   "source": [
    "#### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e860971e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_random_forest_classifier(data_features, data_labels):\n",
    "    \n",
    "    print(\"\\nPerforming Random Forest Classification\\n\")\n",
    "\n",
    "    # get a list of models to evaluate\n",
    "    def get_models():\n",
    "        models = dict()\n",
    "        # explore ratios from 10% to 100% in 10% increments\n",
    "        for i in np.arange(0.1, 1.1, 0.1):\n",
    "            key = '%.1f' % i\n",
    "            # set max_samples=None to use 100%\n",
    "            if i == 1.0:\n",
    "                i = None\n",
    "            models[key] = RandomForestClassifier(max_samples=i)\n",
    "        return models\n",
    "    \n",
    "    models = get_models()\n",
    "    for name, model in models.items():\n",
    "        print('\\n>{}'.format(name))\n",
    "        perform_stratified_sampling(data_features, data_labels, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f74c6147",
   "metadata": {},
   "source": [
    "### Gaussian Naive-Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "87d9a15f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_gaussian_naive_bayes(X_train, y_train, X_test, y_test, file_name, reporting_df):\n",
    "    \n",
    "    print(\"\\nPerforming Gaussian Naive Bayes\\n\")\n",
    "    \n",
    "    gnb = GaussianNB()\n",
    "    gnb.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = gnb.predict(X_test)\n",
    "    \n",
    "    return make_report(X_test, y_test, y_pred, gnb, \"Gaussian Naive Bayes\", file_name, reporting_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e96447",
   "metadata": {},
   "source": [
    "### Read Data Files (xlsx) and run models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "582d0a3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading File RFE15.xlsx\n",
      "\n",
      "Performing 70.0/30.0 Train-Test Split\n",
      "Shape of data: X_train: (3596, 20), y_train: (3596,), X_test: (1542, 20), y_test: (1542,)\n",
      "\n",
      "Performing Logistic Regression\n",
      "\n",
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 0.445712\n",
      "         Iterations: 35\n",
      "\n",
      "Summary for Logit Model:\n",
      "\n",
      "                                   Results: Logit\n",
      "===================================================================================\n",
      "Model:                     Logit                 Pseudo R-squared:      0.147      \n",
      "Dependent Variable:        ActivationLevel       AIC:                   4620.1414  \n",
      "Date:                      2023-03-01 03:43      BIC:                   4751.0298  \n",
      "No. Observations:          5138                  Log-Likelihood:        -2290.1    \n",
      "Df Model:                  19                    LL-Null:               -2683.8    \n",
      "Df Residuals:              5118                  LLR p-value:           9.7172e-155\n",
      "Converged:                 0.0000                Scale:                 1.0000     \n",
      "No. Iterations:            35.0000                                                 \n",
      "-----------------------------------------------------------------------------------\n",
      "                    Coef.    Std.Err.      z    P>|z|      [0.025         0.975]   \n",
      "-----------------------------------------------------------------------------------\n",
      "ASSAULT            -0.7696       0.2530 -3.0414 0.0024        -1.2655       -0.2736\n",
      "OTHER              -0.6936       0.1839 -3.7708 0.0002        -1.0540       -0.3331\n",
      "STAB               -1.4990       0.1971 -7.6041 0.0000        -1.8854       -1.1127\n",
      "IVFunk              0.6793       0.2098  3.2371 0.0012         0.2680        1.0905\n",
      "PELVIC              0.8847       0.3389  2.6104 0.0090         0.2204        1.5489\n",
      "SUCK                0.6591       0.2141  3.0785 0.0021         0.2395        1.0787\n",
      "NEEDLE              0.7879       0.3529  2.2327 0.0256         0.0962        1.4796\n",
      "CPR                -1.9156       0.2837 -6.7510 0.0000        -2.4717       -1.3594\n",
      "ChestTube           1.3392       0.1020 13.1337 0.0000         1.1393        1.5390\n",
      "EmergentIntubation  0.8934       0.1395  6.4062 0.0000         0.6201        1.1668\n",
      "ICP                 1.7017       0.3582  4.7509 0.0000         0.9997        2.4038\n",
      "Craniotomy          1.8853       0.5461  3.4521 0.0006         0.8149        2.9557\n",
      "WorstPHSBP          0.0652 7490315.6712  0.0000 1.0000 -14680748.8833 14680749.0136\n",
      "FirstPHGCS         -0.2998       0.4713 -0.6361 0.5247        -1.2235        0.6239\n",
      "WorstPHGCS         -1.1284       0.3955 -2.8528 0.0043        -1.9036       -0.3531\n",
      "FirstPHPulse        0.2082       0.9161  0.2273 0.8202        -1.5873        2.0037\n",
      "BestPHPulse         0.7664       0.9416  0.8139 0.4157        -1.0791        2.6119\n",
      "FirstPHRTS          0.3820       0.4613  0.8281 0.4076        -0.5222        1.2863\n",
      "WorstPHSBPNorm     -2.8849 7490315.6720 -0.0000 1.0000 -14680751.8349 14680746.0651\n",
      "Age                 0.8863       0.1532  5.7861 0.0000         0.5861        1.1866\n",
      "===================================================================================\n",
      "\n",
      "\n",
      "Finding Classification Report\n",
      "\n",
      "\n",
      "Saving model Logistic Regression \n",
      "\n",
      "\n",
      "Performing SVM Classification\n",
      "\n",
      "{'C': 1, 'degree': 2, 'kernel': 'rbf'}\n",
      "\n",
      "Finding Classification Report\n",
      "\n",
      "\n",
      "Saving model SVM \n",
      "\n",
      "\n",
      "Performing KNN Regression\n",
      "\n",
      "{'n_neighbors': 41, 'weights': 'distance'}\n",
      "\n",
      "Finding Classification Report\n",
      "\n",
      "\n",
      "Saving model KNN Regressor \n",
      "\n",
      "\n",
      "Performing KNN Classification\n",
      "\n",
      "20 Features used during classification: ['ASSAULT' 'OTHER' 'STAB' 'IVFunk' 'PELVIC' 'SUCK' 'NEEDLE' 'CPR'\n",
      " 'ChestTube' 'EmergentIntubation' 'ICP' 'Craniotomy' 'WorstPHSBP'\n",
      " 'FirstPHGCS' 'WorstPHGCS' 'FirstPHPulse' 'BestPHPulse' 'FirstPHRTS'\n",
      " 'WorstPHSBPNorm' 'Age']\n",
      "{'n_neighbors': 21, 'weights': 'distance'}\n",
      "\n",
      "Finding Classification Report\n",
      "\n",
      "\n",
      "Saving model KNN Classifier \n",
      "\n",
      "\n",
      "Performing Random Forest Regression\n",
      "\n",
      "Variable: Age                  Importance: 0.25\n",
      "Variable: FirstPHPulse         Importance: 0.12\n",
      "Variable: BestPHPulse          Importance: 0.12\n",
      "Variable: WorstPHSBP           Importance: 0.11\n",
      "Variable: WorstPHSBPNorm       Importance: 0.1\n",
      "Variable: FirstPHGCS           Importance: 0.07\n",
      "Variable: ChestTube            Importance: 0.05\n",
      "Variable: WorstPHGCS           Importance: 0.05\n",
      "Variable: FirstPHRTS           Importance: 0.05\n",
      "Variable: EmergentIntubation   Importance: 0.02\n",
      "Variable: ASSAULT              Importance: 0.01\n",
      "Variable: OTHER                Importance: 0.01\n",
      "Variable: STAB                 Importance: 0.01\n",
      "Variable: IVFunk               Importance: 0.01\n",
      "Variable: SUCK                 Importance: 0.01\n",
      "Variable: ICP                  Importance: 0.01\n",
      "Variable: Craniotomy           Importance: 0.01\n",
      "Variable: PELVIC               Importance: 0.0\n",
      "Variable: NEEDLE               Importance: 0.0\n",
      "Variable: CPR                  Importance: 0.0\n",
      "\n",
      "Finding Classification Report\n",
      "\n",
      "\n",
      "Saving model RandomForest Regressor \n",
      "\n",
      "\n",
      "Performing Random Forest Classification\n",
      "\n",
      "\n",
      ">0.1\n",
      "Accuracy: 0.809 (0.011)\n",
      "\n",
      ">0.2\n",
      "Accuracy: 0.813 (0.009)\n",
      "\n",
      ">0.3\n",
      "Accuracy: 0.815 (0.012)\n",
      "\n",
      ">0.4\n",
      "Accuracy: 0.813 (0.011)\n",
      "\n",
      ">0.5\n",
      "Accuracy: 0.812 (0.011)\n",
      "\n",
      ">0.6\n",
      "Accuracy: 0.813 (0.010)\n",
      "\n",
      ">0.7\n",
      "Accuracy: 0.810 (0.009)\n",
      "\n",
      ">0.8\n",
      "Accuracy: 0.808 (0.011)\n",
      "\n",
      ">0.9\n",
      "Accuracy: 0.808 (0.011)\n",
      "\n",
      ">1.0\n",
      "Accuracy: 0.807 (0.010)\n",
      "\n",
      "Performing Gaussian Naive Bayes\n",
      "\n",
      "\n",
      "Finding Classification Report\n",
      "\n",
      "\n",
      "Saving model Gaussian Naive Bayes \n",
      "\n",
      "\n",
      "Loading File chi15.xlsx\n",
      "\n",
      "Performing 70.0/30.0 Train-Test Split\n",
      "Shape of data: X_train: (3596, 15), y_train: (3596,), X_test: (1542, 15), y_test: (1542,)\n",
      "\n",
      "Performing Logistic Regression\n",
      "\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.575788\n",
      "         Iterations 7\n",
      "\n",
      "Summary for Logit Model:\n",
      "\n",
      "                            Results: Logit\n",
      "====================================================================\n",
      "Model:                Logit             Pseudo R-squared:  -0.102   \n",
      "Dependent Variable:   ActivationLevel   AIC:               5946.8000\n",
      "Date:                 2023-03-01 03:45  BIC:               6044.9663\n",
      "No. Observations:     5138              Log-Likelihood:    -2958.4  \n",
      "Df Model:             14                LL-Null:           -2683.8  \n",
      "Df Residuals:         5123              LLR p-value:       1.0000   \n",
      "Converged:            1.0000            Scale:             1.0000   \n",
      "No. Iterations:       7.0000                                        \n",
      "--------------------------------------------------------------------\n",
      "                     Coef.  Std.Err.    z     P>|z|   [0.025  0.975]\n",
      "--------------------------------------------------------------------\n",
      "STAB                -1.3786   0.2107  -6.5419 0.0000 -1.7916 -0.9656\n",
      "SPINE               -1.1413   0.0582 -19.6217 0.0000 -1.2553 -1.0273\n",
      "IO                  -0.2934   0.2561  -1.1455 0.2520 -0.7953  0.2086\n",
      "O2                  -0.1767   0.0771  -2.2922 0.0219 -0.3279 -0.0256\n",
      "BVM                  0.1147   0.2188   0.5241 0.6002 -0.3142  0.5436\n",
      "ETT                  0.4495   0.2227   2.0180 0.0436  0.0129  0.8861\n",
      "SUCK                 0.3959   0.2106   1.8801 0.0601 -0.0168  0.8087\n",
      "LMA                  0.2839   0.2977   0.9537 0.3402 -0.2996  0.8675\n",
      "ORAL                 0.2389   0.3171   0.7533 0.4512 -0.3826  0.8604\n",
      "NEEDLE               0.9065   0.3206   2.8279 0.0047  0.2782  1.5348\n",
      "ChestTube            0.6300   0.0994   6.3382 0.0000  0.4352  0.8249\n",
      "EmergentIntubation   0.7835   0.1289   6.0787 0.0000  0.5309  1.0361\n",
      "ICP                  1.4536   0.3423   4.2472 0.0000  0.7828  2.1244\n",
      "Craniotomy           1.9599   0.5294   3.7023 0.0002  0.9223  2.9975\n",
      "BvsPIdx_Penetrating -1.4517   0.1089 -13.3289 0.0000 -1.6652 -1.2383\n",
      "====================================================================\n",
      "\n",
      "\n",
      "Finding Classification Report\n",
      "\n",
      "\n",
      "Saving model Logistic Regression \n",
      "\n",
      "\n",
      "Performing SVM Classification\n",
      "\n",
      "{'C': 1, 'degree': 2, 'kernel': 'poly'}\n",
      "\n",
      "Finding Classification Report\n",
      "\n",
      "\n",
      "Saving model SVM \n",
      "\n",
      "\n",
      "Performing KNN Regression\n",
      "\n",
      "{'n_neighbors': 42, 'weights': 'uniform'}\n",
      "\n",
      "Finding Classification Report\n",
      "\n",
      "\n",
      "Saving model KNN Regressor \n",
      "\n",
      "\n",
      "Performing KNN Classification\n",
      "\n",
      "15 Features used during classification: ['STAB' 'SPINE' 'IO' 'O2' 'BVM' 'ETT' 'SUCK' 'LMA' 'ORAL' 'NEEDLE'\n",
      " 'ChestTube' 'EmergentIntubation' 'ICP' 'Craniotomy' 'BvsPIdx_Penetrating']\n",
      "{'n_neighbors': 33, 'weights': 'uniform'}\n",
      "\n",
      "Finding Classification Report\n",
      "\n",
      "\n",
      "Saving model KNN Classifier \n",
      "\n",
      "\n",
      "Performing Random Forest Regression\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable: ChestTube            Importance: 0.22\n",
      "Variable: EmergentIntubation   Importance: 0.14\n",
      "Variable: O2                   Importance: 0.09\n",
      "Variable: SPINE                Importance: 0.06\n",
      "Variable: BVM                  Importance: 0.06\n",
      "Variable: BvsPIdx_Penetrating  Importance: 0.06\n",
      "Variable: STAB                 Importance: 0.05\n",
      "Variable: IO                   Importance: 0.05\n",
      "Variable: ETT                  Importance: 0.05\n",
      "Variable: SUCK                 Importance: 0.05\n",
      "Variable: ICP                  Importance: 0.04\n",
      "Variable: Craniotomy           Importance: 0.04\n",
      "Variable: LMA                  Importance: 0.03\n",
      "Variable: NEEDLE               Importance: 0.03\n",
      "Variable: ORAL                 Importance: 0.02\n",
      "\n",
      "Finding Classification Report\n",
      "\n",
      "\n",
      "Saving model RandomForest Regressor \n",
      "\n",
      "\n",
      "Performing Random Forest Classification\n",
      "\n",
      "\n",
      ">0.1\n",
      "Accuracy: 0.806 (0.012)\n",
      "\n",
      ">0.2\n",
      "Accuracy: 0.807 (0.012)\n",
      "\n",
      ">0.3\n",
      "Accuracy: 0.807 (0.014)\n",
      "\n",
      ">0.4\n",
      "Accuracy: 0.806 (0.015)\n",
      "\n",
      ">0.5\n",
      "Accuracy: 0.806 (0.013)\n",
      "\n",
      ">0.6\n",
      "Accuracy: 0.804 (0.014)\n",
      "\n",
      ">0.7\n",
      "Accuracy: 0.804 (0.013)\n",
      "\n",
      ">0.8\n",
      "Accuracy: 0.805 (0.014)\n",
      "\n",
      ">0.9\n",
      "Accuracy: 0.805 (0.014)\n",
      "\n",
      ">1.0\n",
      "Accuracy: 0.804 (0.013)\n",
      "\n",
      "Performing Gaussian Naive Bayes\n",
      "\n",
      "\n",
      "Finding Classification Report\n",
      "\n",
      "\n",
      "Saving model Gaussian Naive Bayes \n",
      "\n",
      "\n",
      "Loading File RFE10.xlsx\n",
      "\n",
      "Performing 70.0/30.0 Train-Test Split\n",
      "Shape of data: X_train: (3596, 10), y_train: (3596,), X_test: (1542, 10), y_test: (1542,)\n",
      "\n",
      "Performing Logistic Regression\n",
      "\n",
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 0.455637\n",
      "         Iterations: 35\n",
      "\n",
      "Summary for Logit Model:\n",
      "\n",
      "                           Results: Logit\n",
      "==================================================================\n",
      "Model:              Logit            Pseudo R-squared: 0.128      \n",
      "Dependent Variable: ActivationLevel  AIC:              4702.1307  \n",
      "Date:               2023-03-01 03:46 BIC:              4767.5749  \n",
      "No. Observations:   5138             Log-Likelihood:   -2341.1    \n",
      "Df Model:           9                LL-Null:          -2683.8    \n",
      "Df Residuals:       5128             LLR p-value:      8.9796e-142\n",
      "Converged:          0.0000           Scale:            1.0000     \n",
      "No. Iterations:     35.0000                                       \n",
      "------------------------------------------------------------------\n",
      "                   Coef.  Std.Err.    z     P>|z|   [0.025  0.975]\n",
      "------------------------------------------------------------------\n",
      "STAB              -1.4740   0.1832  -8.0445 0.0000 -1.8331 -1.1149\n",
      "CPR               -1.4694   0.1241 -11.8417 0.0000 -1.7126 -1.2262\n",
      "ChestTube          1.4288   0.0877  16.3000 0.0000  1.2570  1.6006\n",
      "ICP                1.8734   0.3462   5.4120 0.0000  1.1950  2.5519\n",
      "Craniotomy         2.0568   0.5205   3.9519 0.0001  1.0367  3.0769\n",
      "WorstPHSBP         0.5714      nan      nan    nan     nan     nan\n",
      "WorstPHGCS        -1.5704   0.1133 -13.8562 0.0000 -1.7925 -1.3483\n",
      "BestPHPulse        1.5492   0.2903   5.3362 0.0000  0.9802  2.1182\n",
      "WorstPHSBPNorm    -2.7914      nan      nan    nan     nan     nan\n",
      "Age                0.9226      nan      nan    nan     nan     nan\n",
      "==================================================================\n",
      "\n",
      "\n",
      "Finding Classification Report\n",
      "\n",
      "\n",
      "Saving model Logistic Regression \n",
      "\n",
      "\n",
      "Performing SVM Classification\n",
      "\n",
      "{'C': 10, 'degree': 2, 'kernel': 'rbf'}\n",
      "\n",
      "Finding Classification Report\n",
      "\n",
      "\n",
      "Saving model SVM \n",
      "\n",
      "\n",
      "Performing KNN Regression\n",
      "\n",
      "{'n_neighbors': 49, 'weights': 'distance'}\n",
      "\n",
      "Finding Classification Report\n",
      "\n",
      "\n",
      "Saving model KNN Regressor \n",
      "\n",
      "\n",
      "Performing KNN Classification\n",
      "\n",
      "10 Features used during classification: ['STAB' 'CPR' 'ChestTube' 'ICP' 'Craniotomy' 'WorstPHSBP' 'WorstPHGCS'\n",
      " 'BestPHPulse' 'WorstPHSBPNorm' 'Age']\n",
      "{'n_neighbors': 33, 'weights': 'distance'}\n",
      "\n",
      "Finding Classification Report\n",
      "\n",
      "\n",
      "Saving model KNN Classifier \n",
      "\n",
      "\n",
      "Performing Random Forest Regression\n",
      "\n",
      "Variable: Age                  Importance: 0.31\n",
      "Variable: BestPHPulse          Importance: 0.23\n",
      "Variable: WorstPHSBP           Importance: 0.13\n",
      "Variable: WorstPHSBPNorm       Importance: 0.13\n",
      "Variable: WorstPHGCS           Importance: 0.12\n",
      "Variable: ChestTube            Importance: 0.05\n",
      "Variable: STAB                 Importance: 0.01\n",
      "Variable: ICP                  Importance: 0.01\n",
      "Variable: Craniotomy           Importance: 0.01\n",
      "Variable: CPR                  Importance: 0.0\n",
      "\n",
      "Finding Classification Report\n",
      "\n",
      "\n",
      "Saving model RandomForest Regressor \n",
      "\n",
      "\n",
      "Performing Random Forest Classification\n",
      "\n",
      "\n",
      ">0.1\n",
      "Accuracy: 0.807 (0.012)\n",
      "\n",
      ">0.2\n",
      "Accuracy: 0.808 (0.011)\n",
      "\n",
      ">0.3\n",
      "Accuracy: 0.809 (0.010)\n",
      "\n",
      ">0.4\n",
      "Accuracy: 0.810 (0.011)\n",
      "\n",
      ">0.5\n",
      "Accuracy: 0.807 (0.011)\n",
      "\n",
      ">0.6\n",
      "Accuracy: 0.804 (0.010)\n",
      "\n",
      ">0.7\n",
      "Accuracy: 0.803 (0.010)\n",
      "\n",
      ">0.8\n",
      "Accuracy: 0.804 (0.011)\n",
      "\n",
      ">0.9\n",
      "Accuracy: 0.801 (0.011)\n",
      "\n",
      ">1.0\n",
      "Accuracy: 0.800 (0.014)\n",
      "\n",
      "Performing Gaussian Naive Bayes\n",
      "\n",
      "\n",
      "Finding Classification Report\n",
      "\n",
      "\n",
      "Saving model Gaussian Naive Bayes \n",
      "\n",
      "\n",
      "Loading File chi10.xlsx\n",
      "\n",
      "Performing 70.0/30.0 Train-Test Split\n",
      "Shape of data: X_train: (3596, 10), y_train: (3596,), X_test: (1542, 10), y_test: (1542,)\n",
      "\n",
      "Performing Logistic Regression\n",
      "\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.636941\n",
      "         Iterations 7\n",
      "\n",
      "Summary for Logit Model:\n",
      "\n",
      "                           Results: Logit\n",
      "===================================================================\n",
      "Model:               Logit             Pseudo R-squared:  -0.219   \n",
      "Dependent Variable:  ActivationLevel   AIC:               6565.2032\n",
      "Date:                2023-03-01 03:48  BIC:               6630.6474\n",
      "No. Observations:    5138              Log-Likelihood:    -3272.6  \n",
      "Df Model:            9                 LL-Null:           -2683.8  \n",
      "Df Residuals:        5128              LLR p-value:       1.0000   \n",
      "Converged:           1.0000            Scale:             1.0000   \n",
      "No. Iterations:      7.0000                                        \n",
      "-------------------------------------------------------------------\n",
      "                    Coef.  Std.Err.    z     P>|z|   [0.025  0.975]\n",
      "-------------------------------------------------------------------\n",
      "STAB               -2.6611   0.1812 -14.6832 0.0000 -3.0164 -2.3059\n",
      "O2                 -0.6587   0.0709  -9.2957 0.0000 -0.7976 -0.5198\n",
      "BVM                 0.0387   0.1986   0.1947 0.8457 -0.3506  0.4279\n",
      "ETT                 0.0795   0.2095   0.3795 0.7044 -0.3311  0.4900\n",
      "SUCK                0.2715   0.1966   1.3810 0.1673 -0.1138  0.6569\n",
      "NEEDLE              0.8448   0.3053   2.7673 0.0057  0.2464  1.4431\n",
      "ChestTube           0.3251   0.0951   3.4168 0.0006  0.1386  0.5116\n",
      "EmergentIntubation  0.2984   0.1220   2.4462 0.0144  0.0593  0.5375\n",
      "ICP                 1.1364   0.3337   3.4053 0.0007  0.4823  1.7905\n",
      "Craniotomy          1.4482   0.5075   2.8537 0.0043  0.4535  2.4428\n",
      "===================================================================\n",
      "\n",
      "\n",
      "Finding Classification Report\n",
      "\n",
      "\n",
      "Saving model Logistic Regression \n",
      "\n",
      "\n",
      "Performing SVM Classification\n",
      "\n",
      "{'C': 1, 'degree': 2, 'kernel': 'poly'}\n",
      "\n",
      "Finding Classification Report\n",
      "\n",
      "\n",
      "Saving model SVM \n",
      "\n",
      "\n",
      "Performing KNN Regression\n",
      "\n",
      "{'n_neighbors': 40, 'weights': 'uniform'}\n",
      "\n",
      "Finding Classification Report\n",
      "\n",
      "\n",
      "Saving model KNN Regressor \n",
      "\n",
      "\n",
      "Performing KNN Classification\n",
      "\n",
      "10 Features used during classification: ['STAB' 'O2' 'BVM' 'ETT' 'SUCK' 'NEEDLE' 'ChestTube' 'EmergentIntubation'\n",
      " 'ICP' 'Craniotomy']\n",
      "{'n_neighbors': 8, 'weights': 'uniform'}\n",
      "\n",
      "Finding Classification Report\n",
      "\n",
      "\n",
      "Saving model KNN Classifier \n",
      "\n",
      "\n",
      "Performing Random Forest Regression\n",
      "\n",
      "Variable: ChestTube            Importance: 0.29\n",
      "Variable: EmergentIntubation   Importance: 0.18\n",
      "Variable: O2                   Importance: 0.11\n",
      "Variable: STAB                 Importance: 0.09\n",
      "Variable: BVM                  Importance: 0.07\n",
      "Variable: SUCK                 Importance: 0.07\n",
      "Variable: ETT                  Importance: 0.06\n",
      "Variable: ICP                  Importance: 0.05\n",
      "Variable: Craniotomy           Importance: 0.05\n",
      "Variable: NEEDLE               Importance: 0.04\n",
      "\n",
      "Finding Classification Report\n",
      "\n",
      "\n",
      "Saving model RandomForest Regressor \n",
      "\n",
      "\n",
      "Performing Random Forest Classification\n",
      "\n",
      "\n",
      ">0.1\n",
      "Accuracy: 0.804 (0.014)\n",
      "\n",
      ">0.2\n",
      "Accuracy: 0.804 (0.014)\n",
      "\n",
      ">0.3\n",
      "Accuracy: 0.803 (0.014)\n",
      "\n",
      ">0.4\n",
      "Accuracy: 0.804 (0.015)\n",
      "\n",
      ">0.5\n",
      "Accuracy: 0.803 (0.014)\n",
      "\n",
      ">0.6\n",
      "Accuracy: 0.803 (0.015)\n",
      "\n",
      ">0.7\n",
      "Accuracy: 0.803 (0.014)\n",
      "\n",
      ">0.8\n",
      "Accuracy: 0.803 (0.015)\n",
      "\n",
      ">0.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.803 (0.014)\n",
      "\n",
      ">1.0\n",
      "Accuracy: 0.802 (0.014)\n",
      "\n",
      "Performing Gaussian Naive Bayes\n",
      "\n",
      "\n",
      "Finding Classification Report\n",
      "\n",
      "\n",
      "Saving model Gaussian Naive Bayes \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File Name</th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision_Recall</th>\n",
       "      <th>R-Square</th>\n",
       "      <th>Adjusted-R-Square</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RFE15.xlsx</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.820363</td>\n",
       "      <td>{'0': {'precision': 0.8346344925479063, 'recal...</td>\n",
       "      <td>-1.279300</td>\n",
       "      <td>-0.101595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RFE15.xlsx</td>\n",
       "      <td>SVM</td>\n",
       "      <td>0.815824</td>\n",
       "      <td>{'0': {'precision': 0.8192360163710778, 'recal...</td>\n",
       "      <td>-2.930567</td>\n",
       "      <td>-0.129433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RFE15.xlsx</td>\n",
       "      <td>KNN Regressor</td>\n",
       "      <td>0.813878</td>\n",
       "      <td>{'0': {'precision': 0.8223911541119557, 'recal...</td>\n",
       "      <td>-2.219394</td>\n",
       "      <td>-0.141364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RFE15.xlsx</td>\n",
       "      <td>KNN Classifier</td>\n",
       "      <td>0.815824</td>\n",
       "      <td>{'0': {'precision': 0.8277310924369747, 'recal...</td>\n",
       "      <td>-1.690108</td>\n",
       "      <td>-0.129433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RFE15.xlsx</td>\n",
       "      <td>RandomForest Regressor</td>\n",
       "      <td>0.819715</td>\n",
       "      <td>{'0': {'precision': 0.8478581979320532, 'recal...</td>\n",
       "      <td>-0.684041</td>\n",
       "      <td>-0.105572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RFE15.xlsx</td>\n",
       "      <td>Gaussian Naive Bayes</td>\n",
       "      <td>0.789883</td>\n",
       "      <td>{'0': {'precision': 0.845679012345679, 'recall...</td>\n",
       "      <td>-0.567073</td>\n",
       "      <td>-0.288508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>chi15.xlsx</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.817121</td>\n",
       "      <td>{'0': {'precision': 0.8307475317348378, 'recal...</td>\n",
       "      <td>-1.473065</td>\n",
       "      <td>-0.117805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>chi15.xlsx</td>\n",
       "      <td>SVM</td>\n",
       "      <td>0.820363</td>\n",
       "      <td>{'0': {'precision': 0.8304134548002803, 'recal...</td>\n",
       "      <td>-1.602809</td>\n",
       "      <td>-0.097985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>chi15.xlsx</td>\n",
       "      <td>KNN Regressor</td>\n",
       "      <td>0.813878</td>\n",
       "      <td>{'0': {'precision': 0.8188653451811346, 'recal...</td>\n",
       "      <td>-2.829084</td>\n",
       "      <td>-0.137624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>chi15.xlsx</td>\n",
       "      <td>KNN Classifier</td>\n",
       "      <td>0.815824</td>\n",
       "      <td>{'0': {'precision': 0.8205479452054795, 'recal...</td>\n",
       "      <td>-2.657935</td>\n",
       "      <td>-0.125732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>chi15.xlsx</td>\n",
       "      <td>RandomForest Regressor</td>\n",
       "      <td>0.821660</td>\n",
       "      <td>{'0': {'precision': 0.8320449754040758, 'recal...</td>\n",
       "      <td>-1.504178</td>\n",
       "      <td>-0.090058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>chi15.xlsx</td>\n",
       "      <td>Gaussian Naive Bayes</td>\n",
       "      <td>0.800259</td>\n",
       "      <td>{'0': {'precision': 0.8323615160349854, 'recal...</td>\n",
       "      <td>-1.036255</td>\n",
       "      <td>-0.220865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>RFE10.xlsx</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.817121</td>\n",
       "      <td>{'0': {'precision': 0.8293539325842697, 'recal...</td>\n",
       "      <td>-1.587864</td>\n",
       "      <td>-0.114154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>RFE10.xlsx</td>\n",
       "      <td>SVM</td>\n",
       "      <td>0.816472</td>\n",
       "      <td>{'0': {'precision': 0.8202323991797676, 'recal...</td>\n",
       "      <td>-2.775717</td>\n",
       "      <td>-0.118105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>RFE10.xlsx</td>\n",
       "      <td>KNN Regressor</td>\n",
       "      <td>0.811933</td>\n",
       "      <td>{'0': {'precision': 0.8167574931880109, 'recal...</td>\n",
       "      <td>-3.116467</td>\n",
       "      <td>-0.145761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>RFE10.xlsx</td>\n",
       "      <td>KNN Classifier</td>\n",
       "      <td>0.809987</td>\n",
       "      <td>{'0': {'precision': 0.8185567010309278, 'recal...</td>\n",
       "      <td>-2.569191</td>\n",
       "      <td>-0.157614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>RFE10.xlsx</td>\n",
       "      <td>RandomForest Regressor</td>\n",
       "      <td>0.808042</td>\n",
       "      <td>{'0': {'precision': 0.841715976331361, 'recall...</td>\n",
       "      <td>-0.776830</td>\n",
       "      <td>-0.169467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>RFE10.xlsx</td>\n",
       "      <td>Gaussian Naive Bayes</td>\n",
       "      <td>0.798314</td>\n",
       "      <td>{'0': {'precision': 0.8291093410572049, 'recal...</td>\n",
       "      <td>-1.156876</td>\n",
       "      <td>-0.228730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>chi10.xlsx</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.819066</td>\n",
       "      <td>{'0': {'precision': 0.8292512246326103, 'recal...</td>\n",
       "      <td>-1.664268</td>\n",
       "      <td>-0.102301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>chi10.xlsx</td>\n",
       "      <td>SVM</td>\n",
       "      <td>0.811284</td>\n",
       "      <td>{'0': {'precision': 0.8166325835037491, 'recal...</td>\n",
       "      <td>-3.078364</td>\n",
       "      <td>-0.149712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>chi10.xlsx</td>\n",
       "      <td>KNN Regressor</td>\n",
       "      <td>0.806096</td>\n",
       "      <td>{'0': {'precision': 0.8084393837910248, 'recal...</td>\n",
       "      <td>-5.302309</td>\n",
       "      <td>-0.181319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>chi10.xlsx</td>\n",
       "      <td>KNN Classifier</td>\n",
       "      <td>0.815824</td>\n",
       "      <td>{'0': {'precision': 0.8263598326359832, 'recal...</td>\n",
       "      <td>-1.827677</td>\n",
       "      <td>-0.122056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>chi10.xlsx</td>\n",
       "      <td>RandomForest Regressor</td>\n",
       "      <td>0.819066</td>\n",
       "      <td>{'0': {'precision': 0.8311048557353976, 'recal...</td>\n",
       "      <td>-1.502126</td>\n",
       "      <td>-0.102301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>chi10.xlsx</td>\n",
       "      <td>Gaussian Naive Bayes</td>\n",
       "      <td>0.789235</td>\n",
       "      <td>{'0': {'precision': 0.8332092330603127, 'recal...</td>\n",
       "      <td>-0.875161</td>\n",
       "      <td>-0.284043</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     File Name                   Model  Accuracy  \\\n",
       "0   RFE15.xlsx     Logistic Regression  0.820363   \n",
       "1   RFE15.xlsx                     SVM  0.815824   \n",
       "2   RFE15.xlsx           KNN Regressor  0.813878   \n",
       "3   RFE15.xlsx          KNN Classifier  0.815824   \n",
       "4   RFE15.xlsx  RandomForest Regressor  0.819715   \n",
       "5   RFE15.xlsx    Gaussian Naive Bayes  0.789883   \n",
       "6   chi15.xlsx     Logistic Regression  0.817121   \n",
       "7   chi15.xlsx                     SVM  0.820363   \n",
       "8   chi15.xlsx           KNN Regressor  0.813878   \n",
       "9   chi15.xlsx          KNN Classifier  0.815824   \n",
       "10  chi15.xlsx  RandomForest Regressor  0.821660   \n",
       "11  chi15.xlsx    Gaussian Naive Bayes  0.800259   \n",
       "12  RFE10.xlsx     Logistic Regression  0.817121   \n",
       "13  RFE10.xlsx                     SVM  0.816472   \n",
       "14  RFE10.xlsx           KNN Regressor  0.811933   \n",
       "15  RFE10.xlsx          KNN Classifier  0.809987   \n",
       "16  RFE10.xlsx  RandomForest Regressor  0.808042   \n",
       "17  RFE10.xlsx    Gaussian Naive Bayes  0.798314   \n",
       "18  chi10.xlsx     Logistic Regression  0.819066   \n",
       "19  chi10.xlsx                     SVM  0.811284   \n",
       "20  chi10.xlsx           KNN Regressor  0.806096   \n",
       "21  chi10.xlsx          KNN Classifier  0.815824   \n",
       "22  chi10.xlsx  RandomForest Regressor  0.819066   \n",
       "23  chi10.xlsx    Gaussian Naive Bayes  0.789235   \n",
       "\n",
       "                                     Precision_Recall  R-Square  \\\n",
       "0   {'0': {'precision': 0.8346344925479063, 'recal... -1.279300   \n",
       "1   {'0': {'precision': 0.8192360163710778, 'recal... -2.930567   \n",
       "2   {'0': {'precision': 0.8223911541119557, 'recal... -2.219394   \n",
       "3   {'0': {'precision': 0.8277310924369747, 'recal... -1.690108   \n",
       "4   {'0': {'precision': 0.8478581979320532, 'recal... -0.684041   \n",
       "5   {'0': {'precision': 0.845679012345679, 'recall... -0.567073   \n",
       "6   {'0': {'precision': 0.8307475317348378, 'recal... -1.473065   \n",
       "7   {'0': {'precision': 0.8304134548002803, 'recal... -1.602809   \n",
       "8   {'0': {'precision': 0.8188653451811346, 'recal... -2.829084   \n",
       "9   {'0': {'precision': 0.8205479452054795, 'recal... -2.657935   \n",
       "10  {'0': {'precision': 0.8320449754040758, 'recal... -1.504178   \n",
       "11  {'0': {'precision': 0.8323615160349854, 'recal... -1.036255   \n",
       "12  {'0': {'precision': 0.8293539325842697, 'recal... -1.587864   \n",
       "13  {'0': {'precision': 0.8202323991797676, 'recal... -2.775717   \n",
       "14  {'0': {'precision': 0.8167574931880109, 'recal... -3.116467   \n",
       "15  {'0': {'precision': 0.8185567010309278, 'recal... -2.569191   \n",
       "16  {'0': {'precision': 0.841715976331361, 'recall... -0.776830   \n",
       "17  {'0': {'precision': 0.8291093410572049, 'recal... -1.156876   \n",
       "18  {'0': {'precision': 0.8292512246326103, 'recal... -1.664268   \n",
       "19  {'0': {'precision': 0.8166325835037491, 'recal... -3.078364   \n",
       "20  {'0': {'precision': 0.8084393837910248, 'recal... -5.302309   \n",
       "21  {'0': {'precision': 0.8263598326359832, 'recal... -1.827677   \n",
       "22  {'0': {'precision': 0.8311048557353976, 'recal... -1.502126   \n",
       "23  {'0': {'precision': 0.8332092330603127, 'recal... -0.875161   \n",
       "\n",
       "    Adjusted-R-Square  \n",
       "0           -0.101595  \n",
       "1           -0.129433  \n",
       "2           -0.141364  \n",
       "3           -0.129433  \n",
       "4           -0.105572  \n",
       "5           -0.288508  \n",
       "6           -0.117805  \n",
       "7           -0.097985  \n",
       "8           -0.137624  \n",
       "9           -0.125732  \n",
       "10          -0.090058  \n",
       "11          -0.220865  \n",
       "12          -0.114154  \n",
       "13          -0.118105  \n",
       "14          -0.145761  \n",
       "15          -0.157614  \n",
       "16          -0.169467  \n",
       "17          -0.228730  \n",
       "18          -0.102301  \n",
       "19          -0.149712  \n",
       "20          -0.181319  \n",
       "21          -0.122056  \n",
       "22          -0.102301  \n",
       "23          -0.284043  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = glob.glob(\"{}/{}/*.xlsx\".format(data_folder_loc, folder_to_read_for_input_files))\n",
    "\n",
    "for file_path in files:\n",
    "    \n",
    "    file_name = file_path.split(\"/\")[-1]\n",
    "    data = load_dataset(file_path)\n",
    "    data_features, data_labels = data.drop('ActivationLevel', axis=1), data.ActivationLevel\n",
    "    X_train, X_test, y_train, y_test = perform_train_test_split(data_features, data_labels)\n",
    "    print(\"Shape of data: X_train: {}, y_train: {}, X_test: {}, y_test: {}\".format(X_train.shape, y_train.shape, X_test.shape, y_test.shape))\n",
    "    \n",
    "    reporting_df = perform_logistic_regression(X_train, y_train, X_test, y_test, file_name, reporting_df)\n",
    "    reporting_df = perform_svm(X_train, y_train, X_test, y_test, file_name, reporting_df)\n",
    "    reporting_df = perform_knn_regressor(X_train, y_train, X_test, y_test, file_name, reporting_df)\n",
    "    reporting_df = perform_knn_classifier(X_train, y_train, X_test, y_test, file_name, reporting_df)\n",
    "    reporting_df = perform_random_forest_regressor(X_train, y_train, X_test, y_test, file_name, reporting_df)\n",
    "    perform_random_forest_classifier(data_features, data_labels)\n",
    "    reporting_df = perform_gaussian_naive_bayes(X_train, y_train, X_test, y_test, file_name, reporting_df)\n",
    "            \n",
    "reporting_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3a28618e",
   "metadata": {},
   "outputs": [],
   "source": [
    "reporting_df.to_excel(\"{}/{}/{}\".format(data_folder_loc, folder_to_save_model, 'ModelOutput.xlsx'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e49f69",
   "metadata": {},
   "source": [
    "### T-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "47347905",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # That's an impressive list of imports.\n",
    "# import numpy as np\n",
    "# from numpy import linalg\n",
    "# from numpy.linalg import norm\n",
    "# from scipy.spatial.distance import squareform, pdist\n",
    "\n",
    "# # We import sklearn.\n",
    "# import sklearn\n",
    "# from sklearn.manifold import TSNE\n",
    "# from sklearn.datasets import load_digits\n",
    "# from sklearn.preprocessing import scale\n",
    "\n",
    "# # We'll hack a bit with the t-SNE code in sklearn 0.15.2.\n",
    "# from sklearn.metrics.pairwise import pairwise_distances\n",
    "# from sklearn.manifold._t_sne import (_joint_probabilities,\n",
    "#                                     _kl_divergence)\n",
    "# # from sklearn.utils.extmath import _ravel\n",
    "# # Random state.\n",
    "# RS = 20150101\n",
    "\n",
    "# # We'll use matplotlib for graphics.\n",
    "# import matplotlib.pyplot as plt\n",
    "# import matplotlib.patheffects as PathEffects\n",
    "# import matplotlib\n",
    "# %matplotlib inline\n",
    "\n",
    "# # We import seaborn to make nice plots.\n",
    "# import seaborn as sns\n",
    "# sns.set_style('darkgrid')\n",
    "# sns.set_palette('muted')\n",
    "# sns.set_context(\"notebook\", font_scale=1.5,\n",
    "#                 rc={\"lines.linewidth\": 2.5})\n",
    "\n",
    "# # We first reorder the data points according to the handwritten numbers.\n",
    "# X = np.vstack([all_vars_data_dupl[all_vars_data_dupl.FinalNFTI==i].drop(['FinalNFTI', 'MRN', 'LastName', 'EDArrival', 'ISS', 'PHHoTN', 'FinalIntwithin3', 'EDHoTN', 'TFIR', 'ICP', 'Craniotomy'], axis=1)\n",
    "#                for i in range(2)])\n",
    "# y = np.hstack([all_vars_data_dupl[all_vars_data_dupl.FinalNFTI==i].FinalNFTI\n",
    "#                for i in range(2)])\n",
    "\n",
    "# digits_proj = TSNE(random_state=RS).fit_transform(X)\n",
    "\n",
    "# def scatter(x, colors):\n",
    "#     # We choose a color palette with seaborn.\n",
    "#     palette = np.array(sns.color_palette(\"hls\", 2))\n",
    "\n",
    "#     # We create a scatter plot.\n",
    "#     f = plt.figure(figsize=(8, 8))\n",
    "#     ax = plt.subplot(aspect='equal')\n",
    "#     sc = ax.scatter(x[:,0], x[:,1], lw=0, s=40,\n",
    "#                     c=palette[colors.astype(np.int)])\n",
    "#     plt.xlim(-25, 25)\n",
    "#     plt.ylim(-25, 25)\n",
    "#     ax.axis('off')\n",
    "#     ax.axis('tight')\n",
    "\n",
    "#     # We add the labels for each digit.\n",
    "#     txts = []\n",
    "#     for i in range(2):\n",
    "#         # Position of each label.\n",
    "#         xtext, ytext = np.median(x[colors == i, :], axis=0)\n",
    "#         txt = ax.text(xtext, ytext, str(i), fontsize=24)\n",
    "#         txt.set_path_effects([\n",
    "#             PathEffects.Stroke(linewidth=5, foreground=\"w\"),\n",
    "#             PathEffects.Normal()])\n",
    "#         txts.append(txt)\n",
    "\n",
    "#     return f, ax, sc, txts\n",
    "\n",
    "# scatter(digits_proj, y)\n",
    "# # plt.savefig('images/digits_tsne-generated.png', dpi=120)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
